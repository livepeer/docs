### On-chain Setup

In the previous section, we covered the **off-chain** configuration of your AI
Gateway node. This section will explain how to connect your AI Gateway to the
Livepeer AI network to start requesting AI inference jobs **on-chain**.

## Prerequisites

- A dedicated static IP address or domain name for your AI Gateway node
- A funded Ethereum account with enough ETH to cover gas fees and AI inference
  job payments

## Launching your On-chain AI Gateway

Once your AI Gateway is set up **off-chain**, it's time to connect it to the
Livepeer AI network for **on-chain** inference jobs. The process is similar to
setting up a Mainnet Transcoding Network Gateway, with a few extra flags
specific to Livepeer AI. You can refer to the
[Mainnet Transcoding Network Gateway](/gateways/guides/gateway-overview) guide
for more information. Here’s a summary of the key steps:

<Steps>
  <Step title="Verify Off-chain AI Gateway">
    Ensure your AI Gateway node is functioning correctly **off-chain** before connecting it to the Livepeer AI network. Refer to [the previous section](/ai/gateways/start-gateway) for details.
  </Step>
  <Step title="Prepare your Ethereum account">
    Make sure your Ethereum account has enough ETH to cover gas fees and AI inference job payments. For more details, see the [Fund Gateway Guide](/gateways/guides/fund-gateway).
  </Step>
  <Step title="Fund your AI Gateway">
    Deposit enough funds into your AI Gateway to cover the **deposit** and **reserve** needed for AI inference requests. Follow the steps in the [Deposit Gateway Funds via Livepeer CLI](/gateways/guides/fund-gateway#deposit-gateway-funds-via-livepeer-cli) guide.
  </Step>
  <Step title="Configure Transcoding Options">
    Configure transcoding options even though the AI Gateway doesn’t handle transcoding, due to current Livepeer AI software requirements. See the [Transcoding Options](/gateways/guides/transcoding-options) guide for more information.
  </Step>
  <Step title="Launch the AI Gateway">
    Now launch your AI Gateway node. The process is similar to the **docker** or **binary** setup in the [previous section](/ai/gateways/start-gateway), but requires additional flags to enable on-chain functionality. Example:

    - `-aiServiceRegistry`: Ensures that the Gateway is connected to the Livepeer AI network.
    - `-network=arbitrum-one-mainnet`: Connects the AI Gateway to the Arbitrum Mainnet network.
    - `-ethUrl=https://arb1.arbitrum.io/rpc`: Sets the Arbitrum Mainnet RPC URL. Replace it with your own if necessary.
    - `-ethKeystorePath=/root/.lpData/arbitrum-one-mainnet/keystore`: Sets the path to the Ethereum keystore file for the AI Gateway.
    - `-ethAcctAddr <LIVEPEER_AI_ORCH_ETH_ADDRESS>`: Sets the Ethereum account address for the AI Gateway.
    - `-ethPassword=/root/.lpData/.eth_secret`: Sets the path to the Ethereum keystore password file.
    - `-ethOrchAddr=<MAIN_ORCH_ETH_ADDRESS>`: Sets the Ethereum address of the Mainnet Transcoding Network Gateway.
    - `-maxTotalEV=100000000000000`: Ensures the AI Gateway complies with the max ticket value limits in `go-livepeer`.
    - `-maxPricePerUnit=<MAX PRICE in WEI or USD>`: This defaults to 0. Set to acceptable max price in wei (or USD, e.g. 0.02USD) willing to pay. Note: this can impact amount of Orchestrators available to process the work.
    - `-ignoreMaxPriceIfNeeded=<true or false>`: This defaults to false. Set to true if want to process requests if no Orchestrators are under maxPricePerUnit or do not want to use a max price.
    - `-maxPricePerCapability=/path/to/maxPrices.json`: This flag sets the max price per unit for one or many pipeline/models. Refer to the [Set Max Price Per Pipeline and Model](#set-max-price-per-pipeline-and-model-optional) section for more details.

  </Step>
</Steps>

## Set Max Price Per Pipeline and Model (Optional)

To avoid overpaying for AI inference jobs, you can set a maximum price per unit
for each pipeline and model. This feature is optional and can be configured
using the `-maxPricePerCapability` flag. If a price is not set for a specific
pipeline/model, the `-maxPricePerUnit` price will be used. The flag input should
be a JSON file with the specified max prices. The example below demonstrates the
following configurations:

- Set the price for the `image-to-image` pipeline and model
  `ByteDance/SDXL-Lightning` to 1,700,000 wei per unit (pixels).
- Set the price for the `text-to-image` pipeline and model
  `stabilityai/stable-diffusion-3-medium-diffusers` to 4,768,371 wei per unit
  (pixels).
- Set the price for the `upscale` pipeline for all models to 4,768,371 wei per
  unit. The `pixels_per_unit` defaults to `1` if not specified.
- Set the price for the `image-to-video` pipeline for all models to 3,390,842
  wei per unit (pixels).
- Set the price for the `audio-to-text` pipeline for all models to 12,882,811
  wei per unit (milliseconds of audio).

```json
{
  "capabilities_prices": [
    {
      "pipeline": "image-to-image",
      "model_id": "ByteDance/SDXL-Lightning",
      "price_per_unit": 1700000,
      "pixels_per_unit": 1
    },
    {
      "pipeline": "text-to-image",
      "model_id": "stabilityai/stable-diffusion-3-medium-diffusers",
      "price_per_unit": 4768371,
      "pixels_per_unit": 1
    },
    {
      "pipeline": "upscale",
      "model_id": "default",
      "price_per_unit": 4768371
    },
    {
      "pipeline": "image-to-video",
      "price_per_unit": 3390842,
      "pixels_per_unit": 1
    },
    {
      "pipeline": "audio-to-text",
      "price_per_unit": 12882811
    }
  ]
}
```
