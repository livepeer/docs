---
title: Overview
---

Livepeer AI offers a variety of **generative AI pipelines** that applications
can use to request AI inference jobs on the Livepeer network. Currently, the
focus is on Diffusion models developed using Huggingface's
[Diffusers library](https://huggingface.co/docs/diffusers/en/index), but future
updates will extend support to other model types. This section introduces the
available pipelines, the models they support, and provides a basic usage
example. For a comprehensive guide on integrating Livepeer AI into your
application, refer to the [Building on the Livepeer AI Network](/ai/builders/get-started)
section.

## Models on Livepeer AI

### Warm Models

During the **Beta** phase of Livepeer AI, Orchestrators are encouraged to
keep at least **one model** per pipeline active on their GPUs ("warm models").
This approach ensures quicker response times for **early builders** on the
Network. We're optimizing GPU model loading/unloading to relax this requirement.
The current warm models for each pipeline are listed on their respective pages.

<Tip>
  For faster responses with different [Diffusion
  models](https://huggingface.co/docs/diffusers/en/index), request Orchestrators
  to load it on their GPU via the `ai-video` channel in [Discord
  Server](https://discord.gg/livepeer).
</Tip>

### On-Demand Models

Orchestrators can theoretically load **any**
[diffusion model](https://huggingface.co/docs/diffusers/en/index) from
[Hugging Face](https://huggingface.co/models) on-demand, optimizing GPU
resources by loading models only when needed. However, during the **Beta**
phase, Orchestrators need to pre-download a model.

<Note>
  If a specific model you wish to use is not listed on the respective pipeline
  page, submit a [feature
  request](https://github.com/livepeer/ai-worker/issues/new?assignees=&labels=enhancement%2Cmodel&projects=&template=model_request.yml)
  on GitHub to get the model verified and added to the list.
</Note>

## Generative AI Pipelines

The network currently supports the following generative AI pipelines:

<CardGroup cols={2}>
  <Card title="Text-to-Image" icon="image" href="/ai/pipelines/text-to-image">
    The text-to-image pipeline generates high-quality images from text
    descriptions
  </Card>
  <Card title="Image-to-Image" icon="image" href="/ai/pipelines/image-to-image">
    The image-to-image pipeline enables advanced image manipulations, including
    style transfer, image enhancement, and more
  </Card>
  <Card title="Image-to-Video" icon="video" href="/ai/pipelines/image-to-video">
    The image-to-video pipeline creates animated high-quality videos from images
  </Card>
  <Card title="Upscale" icon="image" href="/ai/pipelines/upscale">
    The upscale pipeline transforms low-resolution images into high-quality ones without distortion
    images
  </Card>
  <Card title="Audio-to-Text" icon="message-dots" href="/ai/pipelines/audio-to-text">
    The audio-to-text pipeline uses automatic speech recognition (ASR) to translate audio to text with timestamps
  </Card>
  <Card title="Segment-Anything-2" icon="video" href="/ai/pipelines/segment-anything-2">
    The segment-anything-2 pipeline offers promptable visual segmentation for images and videos.
  </Card>
</CardGroup>
