# !!Auto-generated by 'gen_openapi.py'. DO NOT EDIT!!
openapi: 3.1.0
info:
  title: Livepeer AI Runner
  description: An application to run AI pipelines
  version: 0.0.0
servers:
  - url: https://dream-gateway.livepeer.cloud
    description: Livepeer Cloud Community Gateway
  - url: https://livepeer.studio/api/beta/generate
    description: Livepeer Studio Gateway
paths:
  /text-to-image:
    post:
      tags:
        - generate
      summary: Text To Image
      description: Generate images from text prompts.
      operationId: genTextToImage
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/TextToImageParams'
        required: true
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImageResponse'
                x-speakeasy-name-override: data
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
      security:
        - HTTPBearer: []
      x-speakeasy-name-override: textToImage
      x-codeSamples:
        - lang: typescript
          label: genTextToImage
          source: |-
            import { Livepeer } from "@livepeer/ai";

            const livepeer = new Livepeer({
              httpBearer: "<YOUR_BEARER_TOKEN_HERE>",
            });

            async function run() {
              const result = await livepeer.generate.textToImage({
                prompt: "<value>",
              });

              // Handle the result
              console.log(result);
            }

            run();
        - lang: go
          label: genTextToImage
          source: "package main\n\nimport(\n\t\"context\"\n\tlivepeeraigo \"github.com/livepeer/livepeer-ai-go\"\n\t\"github.com/livepeer/livepeer-ai-go/models/components\"\n\t\"log\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    \n    s := livepeeraigo.New(\n        livepeeraigo.WithSecurity(\"<YOUR_BEARER_TOKEN_HERE>\"),\n    )\n\n    res, err := s.Generate.TextToImage(ctx, components.TextToImageParams{\n        Prompt: \"<value>\",\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n    if res.ImageResponse != nil {\n        // handle response\n    }\n}"
        - lang: python
          label: genTextToImage
          source: |-
            from livepeer_ai import Livepeer

            with Livepeer(
                http_bearer="<YOUR_BEARER_TOKEN_HERE>",
            ) as livepeer:

                res = livepeer.generate.text_to_image(request={
                    "prompt": "<value>",
                })

                assert res.image_response is not None

                # Handle response
                print(res.image_response)
  /image-to-image:
    post:
      tags:
        - generate
      summary: Image To Image
      description: Apply image transformations to a provided image.
      operationId: genImageToImage
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/Body_genImageToImage'
        required: true
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImageResponse'
                x-speakeasy-name-override: data
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
      security:
        - HTTPBearer: []
      x-speakeasy-name-override: imageToImage
      x-codeSamples:
        - lang: typescript
          label: genImageToImage
          source: |-
            import { Livepeer } from "@livepeer/ai";
            import { openAsBlob } from "node:fs";

            const livepeer = new Livepeer({
              httpBearer: "<YOUR_BEARER_TOKEN_HERE>",
            });

            async function run() {
              const result = await livepeer.generate.imageToImage({
                prompt: "<value>",
                image: await openAsBlob("example.file"),
              });

              // Handle the result
              console.log(result);
            }

            run();
        - lang: go
          label: genImageToImage
          source: "package main\n\nimport(\n\t\"context\"\n\tlivepeeraigo \"github.com/livepeer/livepeer-ai-go\"\n\t\"os\"\n\t\"github.com/livepeer/livepeer-ai-go/models/components\"\n\t\"log\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    \n    s := livepeeraigo.New(\n        livepeeraigo.WithSecurity(\"<YOUR_BEARER_TOKEN_HERE>\"),\n    )\n\n    content, fileErr := os.Open(\"example.file\")\n    if fileErr != nil {\n        panic(fileErr)\n    }\n\n\n    res, err := s.Generate.ImageToImage(ctx, components.BodyGenImageToImage{\n        Prompt: \"<value>\",\n        Image: components.Image{\n            FileName: \"example.file\",\n            Content: content,\n        },\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n    if res.ImageResponse != nil {\n        // handle response\n    }\n}"
        - lang: python
          label: genImageToImage
          source: |-
            from livepeer_ai import Livepeer

            with Livepeer(
                http_bearer="<YOUR_BEARER_TOKEN_HERE>",
            ) as livepeer:

                res = livepeer.generate.image_to_image(request={
                    "prompt": "<value>",
                    "image": {
                        "file_name": "example.file",
                        "content": open("example.file", "rb"),
                    },
                })

                assert res.image_response is not None

                # Handle response
                print(res.image_response)
  /image-to-video:
    post:
      tags:
        - generate
      summary: Image To Video
      description: Generate a video from a provided image.
      operationId: genImageToVideo
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/Body_genImageToVideo'
        required: true
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VideoResponse'
                x-speakeasy-name-override: data
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
      security:
        - HTTPBearer: []
      x-speakeasy-name-override: imageToVideo
      x-codeSamples:
        - lang: typescript
          label: genImageToVideo
          source: |-
            import { Livepeer } from "@livepeer/ai";
            import { openAsBlob } from "node:fs";

            const livepeer = new Livepeer({
              httpBearer: "<YOUR_BEARER_TOKEN_HERE>",
            });

            async function run() {
              const result = await livepeer.generate.imageToVideo({
                image: await openAsBlob("example.file"),
              });

              // Handle the result
              console.log(result);
            }

            run();
        - lang: go
          label: genImageToVideo
          source: "package main\n\nimport(\n\t\"context\"\n\tlivepeeraigo \"github.com/livepeer/livepeer-ai-go\"\n\t\"os\"\n\t\"github.com/livepeer/livepeer-ai-go/models/components\"\n\t\"log\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    \n    s := livepeeraigo.New(\n        livepeeraigo.WithSecurity(\"<YOUR_BEARER_TOKEN_HERE>\"),\n    )\n\n    content, fileErr := os.Open(\"example.file\")\n    if fileErr != nil {\n        panic(fileErr)\n    }\n\n\n    res, err := s.Generate.ImageToVideo(ctx, components.BodyGenImageToVideo{\n        Image: components.BodyGenImageToVideoImage{\n            FileName: \"example.file\",\n            Content: content,\n        },\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n    if res.VideoResponse != nil {\n        // handle response\n    }\n}"
        - lang: python
          label: genImageToVideo
          source: |-
            from livepeer_ai import Livepeer

            with Livepeer(
                http_bearer="<YOUR_BEARER_TOKEN_HERE>",
            ) as livepeer:

                res = livepeer.generate.image_to_video(request={
                    "image": {
                        "file_name": "example.file",
                        "content": open("example.file", "rb"),
                    },
                })

                assert res.video_response is not None

                # Handle response
                print(res.video_response)
  /upscale:
    post:
      tags:
        - generate
      summary: Upscale
      description: Upscale an image by increasing its resolution.
      operationId: genUpscale
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/Body_genUpscale'
        required: true
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImageResponse'
                x-speakeasy-name-override: data
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
      security:
        - HTTPBearer: []
      x-speakeasy-name-override: upscale
      x-codeSamples:
        - lang: typescript
          label: genUpscale
          source: |-
            import { Livepeer } from "@livepeer/ai";
            import { openAsBlob } from "node:fs";

            const livepeer = new Livepeer({
              httpBearer: "<YOUR_BEARER_TOKEN_HERE>",
            });

            async function run() {
              const result = await livepeer.generate.upscale({
                prompt: "<value>",
                image: await openAsBlob("example.file"),
              });

              // Handle the result
              console.log(result);
            }

            run();
        - lang: go
          label: genUpscale
          source: "package main\n\nimport(\n\t\"context\"\n\tlivepeeraigo \"github.com/livepeer/livepeer-ai-go\"\n\t\"os\"\n\t\"github.com/livepeer/livepeer-ai-go/models/components\"\n\t\"log\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    \n    s := livepeeraigo.New(\n        livepeeraigo.WithSecurity(\"<YOUR_BEARER_TOKEN_HERE>\"),\n    )\n\n    content, fileErr := os.Open(\"example.file\")\n    if fileErr != nil {\n        panic(fileErr)\n    }\n\n\n    res, err := s.Generate.Upscale(ctx, components.BodyGenUpscale{\n        Prompt: \"<value>\",\n        Image: components.BodyGenUpscaleImage{\n            FileName: \"example.file\",\n            Content: content,\n        },\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n    if res.ImageResponse != nil {\n        // handle response\n    }\n}"
        - lang: python
          label: genUpscale
          source: |-
            from livepeer_ai import Livepeer

            with Livepeer(
                http_bearer="<YOUR_BEARER_TOKEN_HERE>",
            ) as livepeer:

                res = livepeer.generate.upscale(request={
                    "prompt": "<value>",
                    "image": {
                        "file_name": "example.file",
                        "content": open("example.file", "rb"),
                    },
                })

                assert res.image_response is not None

                # Handle response
                print(res.image_response)
  /audio-to-text:
    post:
      tags:
        - generate
      summary: Audio To Text
      description: Transcribe audio files to text.
      operationId: genAudioToText
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/Body_genAudioToText'
        required: true
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TextResponse'
                x-speakeasy-name-override: data
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '413':
          description: Request Entity Too Large
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '415':
          description: Unsupported Media Type
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
      security:
        - HTTPBearer: []
      x-speakeasy-name-override: audioToText
      x-codeSamples:
        - lang: typescript
          label: genAudioToText
          source: |-
            import { Livepeer } from "@livepeer/ai";
            import { openAsBlob } from "node:fs";

            const livepeer = new Livepeer({
              httpBearer: "<YOUR_BEARER_TOKEN_HERE>",
            });

            async function run() {
              const result = await livepeer.generate.audioToText({
                audio: await openAsBlob("example.file"),
              });

              // Handle the result
              console.log(result);
            }

            run();
        - lang: go
          label: genAudioToText
          source: "package main\n\nimport(\n\t\"context\"\n\tlivepeeraigo \"github.com/livepeer/livepeer-ai-go\"\n\t\"os\"\n\t\"github.com/livepeer/livepeer-ai-go/models/components\"\n\t\"log\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    \n    s := livepeeraigo.New(\n        livepeeraigo.WithSecurity(\"<YOUR_BEARER_TOKEN_HERE>\"),\n    )\n\n    content, fileErr := os.Open(\"example.file\")\n    if fileErr != nil {\n        panic(fileErr)\n    }\n\n\n    res, err := s.Generate.AudioToText(ctx, components.BodyGenAudioToText{\n        Audio: components.Audio{\n            FileName: \"example.file\",\n            Content: content,\n        },\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n    if res.TextResponse != nil {\n        // handle response\n    }\n}"
        - lang: python
          label: genAudioToText
          source: |-
            from livepeer_ai import Livepeer

            with Livepeer(
                http_bearer="<YOUR_BEARER_TOKEN_HERE>",
            ) as livepeer:

                res = livepeer.generate.audio_to_text(request={
                    "audio": {
                        "file_name": "example.file",
                        "content": open("example.file", "rb"),
                    },
                })

                assert res.text_response is not None

                # Handle response
                print(res.text_response)
  /segment-anything-2:
    post:
      tags:
        - generate
      summary: Segment Anything 2
      description: Segment objects in an image.
      operationId: genSegmentAnything2
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/Body_genSegmentAnything2'
        required: true
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MasksResponse'
                x-speakeasy-name-override: data
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
      security:
        - HTTPBearer: []
      x-speakeasy-name-override: segmentAnything2
      x-codeSamples:
        - lang: typescript
          label: genSegmentAnything2
          source: |-
            import { Livepeer } from "@livepeer/ai";
            import { openAsBlob } from "node:fs";

            const livepeer = new Livepeer({
              httpBearer: "<YOUR_BEARER_TOKEN_HERE>",
            });

            async function run() {
              const result = await livepeer.generate.segmentAnything2({
                image: await openAsBlob("example.file"),
              });

              // Handle the result
              console.log(result);
            }

            run();
        - lang: go
          label: genSegmentAnything2
          source: "package main\n\nimport(\n\t\"context\"\n\tlivepeeraigo \"github.com/livepeer/livepeer-ai-go\"\n\t\"os\"\n\t\"github.com/livepeer/livepeer-ai-go/models/components\"\n\t\"log\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    \n    s := livepeeraigo.New(\n        livepeeraigo.WithSecurity(\"<YOUR_BEARER_TOKEN_HERE>\"),\n    )\n\n    content, fileErr := os.Open(\"example.file\")\n    if fileErr != nil {\n        panic(fileErr)\n    }\n\n\n    res, err := s.Generate.SegmentAnything2(ctx, components.BodyGenSegmentAnything2{\n        Image: components.BodyGenSegmentAnything2Image{\n            FileName: \"example.file\",\n            Content: content,\n        },\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n    if res.MasksResponse != nil {\n        // handle response\n    }\n}"
        - lang: python
          label: genSegmentAnything2
          source: |-
            from livepeer_ai import Livepeer

            with Livepeer(
                http_bearer="<YOUR_BEARER_TOKEN_HERE>",
            ) as livepeer:

                res = livepeer.generate.segment_anything2(request={
                    "image": {
                        "file_name": "example.file",
                        "content": open("example.file", "rb"),
                    },
                })

                assert res.masks_response is not None

                # Handle response
                print(res.masks_response)
  /llm:
    post:
      tags:
        - generate
      summary: LLM
      description: Generate text using a language model.
      operationId: genLLM
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/LLMRequest'
        required: true
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/LLMResponse'
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
      security:
        - HTTPBearer: []
      x-speakeasy-name-override: llm
      x-codeSamples:
        - lang: typescript
          label: genLLM
          source: |-
            import { Livepeer } from "@livepeer/ai";

            const livepeer = new Livepeer({
              httpBearer: "<YOUR_BEARER_TOKEN_HERE>",
            });

            async function run() {
              const result = await livepeer.generate.llm({
                messages: [
                  {
                    role: "<value>",
                    content: "<value>",
                  },
                ],
              });

              // Handle the result
              console.log(result);
            }

            run();
        - lang: go
          label: genLLM
          source: "package main\n\nimport(\n\t\"context\"\n\tlivepeeraigo \"github.com/livepeer/livepeer-ai-go\"\n\t\"github.com/livepeer/livepeer-ai-go/models/components\"\n\t\"log\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    \n    s := livepeeraigo.New(\n        livepeeraigo.WithSecurity(\"<YOUR_BEARER_TOKEN_HERE>\"),\n    )\n\n    res, err := s.Generate.Llm(ctx, components.LLMRequest{\n        Messages: []components.LLMMessage{\n            components.LLMMessage{\n                Role: \"<value>\",\n                Content: \"<value>\",\n            },\n        },\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n    if res.LLMResponse != nil {\n        // handle response\n    }\n}"
        - lang: python
          label: genLLM
          source: |-
            from livepeer_ai import Livepeer

            with Livepeer(
                http_bearer="<YOUR_BEARER_TOKEN_HERE>",
            ) as livepeer:

                res = livepeer.generate.llm(request={
                    "messages": [
                        {
                            "role": "<value>",
                            "content": "<value>",
                        },
                    ],
                })

                assert res.llm_response is not None

                # Handle response
                print(res.llm_response)
  /image-to-text:
    post:
      tags:
        - generate
      summary: Image To Text
      description: Transform image files to text.
      operationId: genImageToText
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/Body_genImageToText'
        required: true
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImageToTextResponse'
                x-speakeasy-name-override: data
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '413':
          description: Request Entity Too Large
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
      security:
        - HTTPBearer: []
      x-speakeasy-name-override: imageToText
      x-codeSamples:
        - lang: typescript
          label: genImageToText
          source: |-
            import { Livepeer } from "@livepeer/ai";
            import { openAsBlob } from "node:fs";

            const livepeer = new Livepeer({
              httpBearer: "<YOUR_BEARER_TOKEN_HERE>",
            });

            async function run() {
              const result = await livepeer.generate.imageToText({
                image: await openAsBlob("example.file"),
              });

              // Handle the result
              console.log(result);
            }

            run();
        - lang: go
          label: genImageToText
          source: "package main\n\nimport(\n\t\"context\"\n\tlivepeeraigo \"github.com/livepeer/livepeer-ai-go\"\n\t\"os\"\n\t\"github.com/livepeer/livepeer-ai-go/models/components\"\n\t\"log\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    \n    s := livepeeraigo.New(\n        livepeeraigo.WithSecurity(\"<YOUR_BEARER_TOKEN_HERE>\"),\n    )\n\n    content, fileErr := os.Open(\"example.file\")\n    if fileErr != nil {\n        panic(fileErr)\n    }\n\n\n    res, err := s.Generate.ImageToText(ctx, components.BodyGenImageToText{\n        Image: components.BodyGenImageToTextImage{\n            FileName: \"example.file\",\n            Content: content,\n        },\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n    if res.ImageToTextResponse != nil {\n        // handle response\n    }\n}"
        - lang: python
          label: genImageToText
          source: |-
            from livepeer_ai import Livepeer

            with Livepeer(
                http_bearer="<YOUR_BEARER_TOKEN_HERE>",
            ) as livepeer:

                res = livepeer.generate.image_to_text(request={
                    "image": {
                        "file_name": "example.file",
                        "content": open("example.file", "rb"),
                    },
                })

                assert res.image_to_text_response is not None

                # Handle response
                print(res.image_to_text_response)
  /live-video-to-video:
    post:
      tags:
        - generate
      summary: Live Video To Video
      description: Apply transformations to a live video streamed to the returned endpoints.
      operationId: genLiveVideoToVideo
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/LiveVideoToVideoParams'
        required: true
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/LiveVideoToVideoResponse'
                x-speakeasy-name-override: data
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
      security:
        - HTTPBearer: []
      x-speakeasy-name-override: liveVideoToVideo
      x-codeSamples:
        - lang: typescript
          label: genLiveVideoToVideo
          source: |-
            import { Livepeer } from "@livepeer/ai";

            const livepeer = new Livepeer({
              httpBearer: "<YOUR_BEARER_TOKEN_HERE>",
            });

            async function run() {
              const result = await livepeer.generate.liveVideoToVideo({
                subscribeUrl: "https://soulful-lava.org/",
                publishUrl: "https://vain-tabletop.biz",
              });

              // Handle the result
              console.log(result);
            }

            run();
        - lang: go
          label: genLiveVideoToVideo
          source: "package main\n\nimport(\n\t\"context\"\n\tlivepeeraigo \"github.com/livepeer/livepeer-ai-go\"\n\t\"github.com/livepeer/livepeer-ai-go/models/components\"\n\t\"log\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    \n    s := livepeeraigo.New(\n        livepeeraigo.WithSecurity(\"<YOUR_BEARER_TOKEN_HERE>\"),\n    )\n\n    res, err := s.Generate.LiveVideoToVideo(ctx, components.LiveVideoToVideoParams{\n        SubscribeURL: \"https://soulful-lava.org/\",\n        PublishURL: \"https://vain-tabletop.biz\",\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n    if res.LiveVideoToVideoResponse != nil {\n        // handle response\n    }\n}"
        - lang: python
          label: genLiveVideoToVideo
          source: |-
            from livepeer_ai import Livepeer

            with Livepeer(
                http_bearer="<YOUR_BEARER_TOKEN_HERE>",
            ) as livepeer:

                res = livepeer.generate.live_video_to_video(request={
                    "subscribe_url": "https://soulful-lava.org/",
                    "publish_url": "https://vain-tabletop.biz",
                })

                assert res.live_video_to_video_response is not None

                # Handle response
                print(res.live_video_to_video_response)
  /text-to-speech:
    post:
      tags:
        - generate
      summary: Text To Speech
      description: Generate a text-to-speech audio file based on the provided text input and speaker description.
      operationId: genTextToSpeech
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/TextToSpeechParams'
        required: true
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AudioResponse'
                x-speakeasy-name-override: data
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPError'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
      security:
        - HTTPBearer: []
      x-speakeasy-name-override: textToSpeech
      x-codeSamples:
        - lang: typescript
          label: genTextToSpeech
          source: |-
            import { Livepeer } from "@livepeer/ai";

            const livepeer = new Livepeer({
              httpBearer: "<YOUR_BEARER_TOKEN_HERE>",
            });

            async function run() {
              const result = await livepeer.generate.textToSpeech({});

              // Handle the result
              console.log(result);
            }

            run();
        - lang: go
          label: genTextToSpeech
          source: "package main\n\nimport(\n\t\"context\"\n\tlivepeeraigo \"github.com/livepeer/livepeer-ai-go\"\n\t\"github.com/livepeer/livepeer-ai-go/models/components\"\n\t\"log\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    \n    s := livepeeraigo.New(\n        livepeeraigo.WithSecurity(\"<YOUR_BEARER_TOKEN_HERE>\"),\n    )\n\n    res, err := s.Generate.TextToSpeech(ctx, components.TextToSpeechParams{})\n    if err != nil {\n        log.Fatal(err)\n    }\n    if res.AudioResponse != nil {\n        // handle response\n    }\n}"
        - lang: python
          label: genTextToSpeech
          source: |-
            from livepeer_ai import Livepeer

            with Livepeer(
                http_bearer="<YOUR_BEARER_TOKEN_HERE>",
            ) as livepeer:

                res = livepeer.generate.text_to_speech(request={})

                assert res.audio_response is not None

                # Handle response
                print(res.audio_response)
components:
  schemas:
    APIError:
      properties:
        msg:
          type: string
          title: Msg
          description: The error message.
      type: object
      required:
        - msg
      title: APIError
      description: API error response model.
    AudioResponse:
      properties:
        audio:
          allOf:
            - $ref: '#/components/schemas/MediaURL'
          description: The generated audio.
      type: object
      required:
        - audio
      title: AudioResponse
      description: Response model for audio generation.
    Body_genAudioToText:
      properties:
        audio:
          type: string
          format: binary
          title: Audio
          description: Uploaded audio file to be transcribed.
        model_id:
          type: string
          title: Model Id
          description: Hugging Face model ID used for transcription.
          default: ''
        return_timestamps:
          type: string
          title: Return Timestamps
          description: 'Return timestamps for the transcribed text. Supported values: ''sentence'', ''word'', or a string boolean (''true'' or ''false''). Default is ''true'' (''sentence''). ''false'' means no timestamps. ''word'' means word-based timestamps.'
          default: 'true'
      type: object
      required:
        - audio
        - model_id
      title: Body_genAudioToText
    Body_genImageToImage:
      properties:
        prompt:
          type: string
          title: Prompt
          description: Text prompt(s) to guide image generation.
        image:
          type: string
          format: binary
          title: Image
          description: Uploaded image to modify with the pipeline.
        model_id:
          type: string
          title: Model Id
          description: Hugging Face model ID used for image generation.
          default: ''
        loras:
          type: string
          title: Loras
          description: 'A LoRA (Low-Rank Adaptation) model and its corresponding weight for image generation. Example: { "latent-consistency/lcm-lora-sdxl": 1.0, "nerijs/pixel-art-xl": 1.2}.'
          default: ''
        strength:
          type: number
          title: Strength
          description: Degree of transformation applied to the reference image (0 to 1).
          default: 0.8
        guidance_scale:
          type: number
          title: Guidance Scale
          description: Encourages model to generate images closely linked to the text prompt (higher values may reduce image quality).
          default: 7.5
        image_guidance_scale:
          type: number
          title: Image Guidance Scale
          description: Degree to which the generated image is pushed towards the initial image.
          default: 1.5
        negative_prompt:
          type: string
          title: Negative Prompt
          description: Text prompt(s) to guide what to exclude from image generation. Ignored if guidance_scale < 1.
          default: ''
        safety_check:
          type: boolean
          title: Safety Check
          description: Perform a safety check to estimate if generated images could be offensive or harmful.
          default: true
        seed:
          type: integer
          title: Seed
          description: Seed for random number generation.
        num_inference_steps:
          type: integer
          title: Num Inference Steps
          description: Number of denoising steps. More steps usually lead to higher quality images but slower inference. Modulated by strength.
          default: 100
        num_images_per_prompt:
          type: integer
          title: Num Images Per Prompt
          description: Number of images to generate per prompt.
          default: 1
      type: object
      required:
        - prompt
        - image
        - model_id
      title: Body_genImageToImage
    Body_genImageToText:
      properties:
        image:
          type: string
          format: binary
          title: Image
          description: Uploaded image to transform with the pipeline.
        prompt:
          type: string
          title: Prompt
          description: Text prompt(s) to guide transformation.
          default: ''
        model_id:
          type: string
          title: Model Id
          description: Hugging Face model ID used for transformation.
          default: ''
      type: object
      required:
        - image
        - model_id
      title: Body_genImageToText
    Body_genImageToVideo:
      properties:
        image:
          type: string
          format: binary
          title: Image
          description: Uploaded image to generate a video from.
        model_id:
          type: string
          title: Model Id
          description: Hugging Face model ID used for video generation.
          default: ''
        height:
          type: integer
          title: Height
          description: The height in pixels of the generated video.
          default: 576
        width:
          type: integer
          title: Width
          description: The width in pixels of the generated video.
          default: 1024
        fps:
          type: integer
          title: Fps
          description: The frames per second of the generated video.
          default: 6
        motion_bucket_id:
          type: integer
          title: Motion Bucket Id
          description: Used for conditioning the amount of motion for the generation. The higher the number the more motion will be in the video.
          default: 127
        noise_aug_strength:
          type: number
          title: Noise Aug Strength
          description: Amount of noise added to the conditioning image. Higher values reduce resemblance to the conditioning image and increase motion.
          default: 0.02
        safety_check:
          type: boolean
          title: Safety Check
          description: Perform a safety check to estimate if generated images could be offensive or harmful.
          default: true
        seed:
          type: integer
          title: Seed
          description: Seed for random number generation.
        num_inference_steps:
          type: integer
          title: Num Inference Steps
          description: Number of denoising steps. More steps usually lead to higher quality images but slower inference. Modulated by strength.
          default: 25
      type: object
      required:
        - image
        - model_id
      title: Body_genImageToVideo
    Body_genSegmentAnything2:
      properties:
        image:
          type: string
          format: binary
          title: Image
          description: Image to segment.
        model_id:
          type: string
          title: Model Id
          description: Hugging Face model ID used for image generation.
          default: ''
        point_coords:
          type: string
          title: Point Coords
          description: Nx2 array of point prompts to the model, where each point is in (X,Y) in pixels.
        point_labels:
          type: string
          title: Point Labels
          description: Labels for the point prompts, where 1 indicates a foreground point and 0 indicates a background point.
        box:
          type: string
          title: Box
          description: A length 4 array given as a box prompt to the model, in XYXY format.
        mask_input:
          type: string
          title: Mask Input
          description: A low-resolution mask input to the model, typically from a previous prediction iteration, with the form 1xHxW (H=W=256 for SAM).
        multimask_output:
          type: boolean
          title: Multimask Output
          description: If true, the model will return three masks for ambiguous input prompts, often producing better masks than a single prediction.
          default: true
        return_logits:
          type: boolean
          title: Return Logits
          description: If true, returns un-thresholded mask logits instead of a binary mask.
          default: true
        normalize_coords:
          type: boolean
          title: Normalize Coords
          description: If true, the point coordinates will be normalized to the range [0,1], with point_coords expected to be with respect to image dimensions.
          default: true
      type: object
      required:
        - image
        - model_id
      title: Body_genSegmentAnything2
    Body_genUpscale:
      properties:
        prompt:
          type: string
          title: Prompt
          description: Text prompt(s) to guide upscaled image generation.
        image:
          type: string
          format: binary
          title: Image
          description: Uploaded image to modify with the pipeline.
        model_id:
          type: string
          title: Model Id
          description: Hugging Face model ID used for upscaled image generation.
          default: ''
        safety_check:
          type: boolean
          title: Safety Check
          description: Perform a safety check to estimate if generated images could be offensive or harmful.
          default: true
        seed:
          type: integer
          title: Seed
          description: Seed for random number generation.
        num_inference_steps:
          type: integer
          title: Num Inference Steps
          description: Number of denoising steps. More steps usually lead to higher quality images but slower inference. Modulated by strength.
          default: 75
      type: object
      required:
        - prompt
        - image
        - model_id
      title: Body_genUpscale
    Chunk:
      properties:
        timestamp:
          items: {}
          type: array
          title: Timestamp
          description: The timestamp of the chunk.
        text:
          type: string
          title: Text
          description: The text of the chunk.
      type: object
      required:
        - timestamp
        - text
      title: Chunk
      description: A chunk of text with a timestamp.
    HTTPError:
      properties:
        detail:
          allOf:
            - $ref: '#/components/schemas/APIError'
          description: Detailed error information.
      type: object
      required:
        - detail
      title: HTTPError
      description: HTTP error response model.
    HTTPValidationError:
      properties:
        detail:
          items:
            $ref: '#/components/schemas/ValidationError'
          type: array
          title: Detail
      type: object
      title: HTTPValidationError
    ImageResponse:
      properties:
        images:
          items:
            $ref: '#/components/schemas/Media'
          type: array
          title: Images
          description: The generated images.
      type: object
      required:
        - images
      title: ImageResponse
      description: Response model for image generation.
    ImageToTextResponse:
      properties:
        text:
          type: string
          title: Text
          description: The generated text.
      type: object
      required:
        - text
      title: ImageToTextResponse
      description: Response model for text generation.
    LLMChoice:
      properties:
        index:
          type: integer
          title: Index
        finish_reason:
          type: string
          title: Finish Reason
          default: ''
        delta:
          allOf:
            - $ref: '#/components/schemas/LLMMessage'
        message:
          allOf:
            - $ref: '#/components/schemas/LLMMessage'
      type: object
      required:
        - index
      title: LLMChoice
    LLMMessage:
      properties:
        role:
          type: string
          title: Role
        content:
          type: string
          title: Content
      type: object
      required:
        - role
        - content
      title: LLMMessage
    LLMRequest:
      properties:
        messages:
          items:
            $ref: '#/components/schemas/LLMMessage'
          type: array
          title: Messages
        model:
          type: string
          title: Model
          default: ''
        temperature:
          type: number
          title: Temperature
          default: 0.7
        max_tokens:
          type: integer
          title: Max Tokens
          default: 256
        top_p:
          type: number
          title: Top P
          default: 1.0
        top_k:
          type: integer
          title: Top K
          default: -1
        stream:
          type: boolean
          title: Stream
          default: false
      type: object
      required:
        - messages
      title: LLMRequest
    LLMResponse:
      properties:
        id:
          type: string
          title: Id
        model:
          type: string
          title: Model
        created:
          type: integer
          title: Created
        usage:
          $ref: '#/components/schemas/LLMTokenUsage'
        choices:
          items:
            $ref: '#/components/schemas/LLMChoice'
          type: array
          title: Choices
      type: object
      required:
        - id
        - model
        - created
        - usage
        - choices
      title: LLMResponse
    LLMTokenUsage:
      properties:
        prompt_tokens:
          type: integer
          title: Prompt Tokens
        completion_tokens:
          type: integer
          title: Completion Tokens
        total_tokens:
          type: integer
          title: Total Tokens
      type: object
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      title: LLMTokenUsage
    LiveVideoToVideoParams:
      properties:
        subscribe_url:
          type: string
          title: Subscribe Url
          description: Source URL of the incoming stream to subscribe to.
        publish_url:
          type: string
          title: Publish Url
          description: Destination URL of the outgoing stream to publish.
        control_url:
          type: string
          title: Control Url
          description: URL for subscribing via Trickle protocol for updates in the live video-to-video generation params.
          default: ''
        events_url:
          type: string
          title: Events Url
          description: URL for publishing events via Trickle protocol for pipeline status and logs.
          default: ''
        model_id:
          type: string
          title: Model Id
          description: Name of the pipeline to run in the live video to video job. Notice that this is named model_id for consistency with other routes, but it does not refer to a Hugging Face model ID. The exact model(s) depends on the pipeline implementation and might be configurable via the `params` argument.
          default: ''
        params:
          type: object
          title: Params
          description: Initial parameters for the pipeline.
          default: {}
      type: object
      required:
        - subscribe_url
        - publish_url
        - model_id
      title: LiveVideoToVideoParams
    LiveVideoToVideoResponse:
      properties:
        subscribe_url:
          type: string
          title: Subscribe Url
          description: Source URL of the incoming stream to subscribe to
        publish_url:
          type: string
          title: Publish Url
          description: Destination URL of the outgoing stream to publish to
        control_url:
          type: string
          title: Control Url
          description: URL for updating the live video-to-video generation
          default: ''
        events_url:
          type: string
          title: Events Url
          description: URL for subscribing to events for pipeline status and logs
          default: ''
      type: object
      required:
        - subscribe_url
        - publish_url
      title: LiveVideoToVideoResponse
      description: Response model for live video-to-video generation.
    MasksResponse:
      properties:
        masks:
          type: string
          title: Masks
          description: The generated masks.
        scores:
          type: string
          title: Scores
          description: The model's confidence scores for each generated mask.
        logits:
          type: string
          title: Logits
          description: The raw, unnormalized predictions (logits) for the masks.
      type: object
      required:
        - masks
        - scores
        - logits
      title: MasksResponse
      description: Response model for object segmentation.
    Media:
      properties:
        url:
          type: string
          title: Url
          description: The URL where the media can be accessed.
        seed:
          type: integer
          title: Seed
          description: The seed used to generate the media.
        nsfw:
          type: boolean
          title: Nsfw
          description: Whether the media was flagged as NSFW.
      type: object
      required:
        - url
        - seed
        - nsfw
      title: Media
      description: A media object containing information about the generated media.
    MediaURL:
      properties:
        url:
          type: string
          title: Url
          description: The URL where the media can be accessed.
      type: object
      required:
        - url
      title: MediaURL
      description: A URL from which media can be accessed.
    TextResponse:
      properties:
        text:
          type: string
          title: Text
          description: The generated text.
        chunks:
          items:
            $ref: '#/components/schemas/Chunk'
          type: array
          title: Chunks
          description: The generated text chunks.
      type: object
      required:
        - text
        - chunks
      title: TextResponse
      description: Response model for text generation.
    TextToImageParams:
      properties:
        model_id:
          type: string
          title: Model Id
          description: Hugging Face model ID used for image generation.
          default: ''
        loras:
          type: string
          title: Loras
          description: 'A LoRA (Low-Rank Adaptation) model and its corresponding weight for image generation. Example: { "latent-consistency/lcm-lora-sdxl": 1.0, "nerijs/pixel-art-xl": 1.2}.'
          default: ''
        prompt:
          type: string
          title: Prompt
          description: Text prompt(s) to guide image generation. Separate multiple prompts with '|' if supported by the model.
        height:
          type: integer
          title: Height
          description: The height in pixels of the generated image.
          default: 576
        width:
          type: integer
          title: Width
          description: The width in pixels of the generated image.
          default: 1024
        guidance_scale:
          type: number
          title: Guidance Scale
          description: Encourages model to generate images closely linked to the text prompt (higher values may reduce image quality).
          default: 7.5
        negative_prompt:
          type: string
          title: Negative Prompt
          description: Text prompt(s) to guide what to exclude from image generation. Ignored if guidance_scale < 1.
          default: ''
        safety_check:
          type: boolean
          title: Safety Check
          description: Perform a safety check to estimate if generated images could be offensive or harmful.
          default: true
        seed:
          type: integer
          title: Seed
          description: Seed for random number generation.
        num_inference_steps:
          type: integer
          title: Num Inference Steps
          description: Number of denoising steps. More steps usually lead to higher quality images but slower inference. Modulated by strength.
          default: 50
        num_images_per_prompt:
          type: integer
          title: Num Images Per Prompt
          description: Number of images to generate per prompt.
          default: 1
      type: object
      required:
        - prompt
        - model_id
      title: TextToImageParams
    TextToSpeechParams:
      properties:
        model_id:
          type: string
          title: Model Id
          description: Hugging Face model ID used for text to speech generation.
          default: ''
        text:
          type: string
          title: Text
          description: Text input for speech generation.
          default: ''
        description:
          type: string
          title: Description
          description: Description of speaker to steer text to speech generation.
          default: A male speaker delivers a slightly expressive and animated speech with a moderate speed and pitch.
      type: object
      title: TextToSpeechParams
      required:
        - model_id
    ValidationError:
      properties:
        loc:
          items:
            anyOf:
              - type: string
              - type: integer
          type: array
          title: Location
        msg:
          type: string
          title: Message
        type:
          type: string
          title: Error Type
      type: object
      required:
        - loc
        - msg
        - type
      title: ValidationError
    VideoResponse:
      properties:
        images:
          items:
            $ref: '#/components/schemas/Media'
          type: array
          title: Images
          description: The generated images.
      type: object
      required:
        - images
      title: VideoResponse
      description: Response model for image generation.
  securitySchemes:
    HTTPBearer:
      type: http
      scheme: bearer
